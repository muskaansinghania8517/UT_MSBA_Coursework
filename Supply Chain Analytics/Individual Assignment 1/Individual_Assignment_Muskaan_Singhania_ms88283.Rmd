---
title: "Supply Chain Individual assignment 1 - Muskaan Singhania (ms88283)"
output:
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---



------------------------------------------------------------------------

<center>

## Individual Assignment #1: ETS Laboratory

#### Due: Nov. 3 (Before Class)

#### (40 points)

</center>

------------------------------------------------------------------------

You have been hired by a company in the hospitality business to help them plan the staffing levels for the following year. The company operates resorts in three regions of the New South Wales of Australia; the three regions are the **Sydney**, the **South Coast** and the **North Coast NSW** areas.

As it takes time to hire new personnel and it is necessary for any new employee to undergo a detailed training program before starting to work, the company needs to plan its personnel requirements one year in advance. Furthermore, as it is possible for the company to transfer qualified personnel between regions, they are interested only in an aggregate forecast of their demand

As the company caters to **Holiday** travelers, and it has been growing faster than the market (i.e., it has been gaining market share), the Chief Commercial Officer estimates that next year they will have respectively (3%, 4%, 4%) of only the **Holiday** travelers in the (**Sydney**, **South Coast**, and **North Coast NSW**) regions respectively. Furthermore based on prior experience they anticipate that each traveler will stay respectively (5,2,2) hotel-nights in (**Sydney**, **South Coast**, and **North Coast NSW**) respectively

To forecast demand in hotel-nights use the **tourism** data set in **fpp3**. This data set reports the quarterly trips (in thousands) to different destinations, and as this data set has a *tsibble* structure, you can use **tidyverse** functions to subset the time-series of interest.

For the purposes of this assignment ignore all data before **2008 Q1** and use the data from **2008 Q1** through **2016 Q4** as a training set and the four quarters of **2017** as a testing set.

If you need to dust-off the tidyverse functions, a good reference is the electronic book [*R for Data Science*](https://r4ds.had.co.nz/) or alternatively, if you only need a quick refresher of the **dplyr** and **tidyr** functions you can use the following [*Data Wrangling Cheat Sheet*](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

### Part I. Model-Aggregation Forecast

#### Q1. After sub-setting for the time-series of interest in the **tourism** data set (a *tsibble*), add to the restricted set the corresponding demand time-series, by creating a column called *Demand* for each of the corresponding regions of interest. The *Demand* column should contain the hotel-nights (in thousands) corresponding to each of the *Trips* observations. After creating the *Demand* column, the code below uses the **group_by()** function to aggregate demand across regions creating the *AGG.D* column with the total demand and you are asked to find the best **ETS** model for each *Demand* time-series. In addition to the automatic fit, one of your colleagues suggest that you should find the best model that includes an additive trend "A" and the best model that includes an additive-damped "Ad" trend, as the automatic selection is based only on the AICc criterion, and the models with trend may be better under the *BIC* criterion. Report the best model as well as the corresponding *AICc* and *BIC*. What is the best model according to the information criteria?

```{r, warning=FALSE, echo=FALSE, results = FALSE, message=FALSE}
library(fpp3)
```


```{r, warning=FALSE}
#Creating Demand time-series after subsetting
tourism %>% 
  filter(Quarter >= yearquarter("2008 Q1")) %>%
  filter(Purpose == "Holiday" & State == "New South Wales") %>%
  filter(Region %in% c("North Coast NSW","South Coast","Sydney")) %>%
  mutate(Demand = case_when(
    Region == "Sydney" ~ 0.03*Trips*5,
    Region == "South Coast" ~ 0.04*Trips*2,
    Region == "North Coast NSW" ~ 0.04*Trips*2
  )) -> D

D %>%
  group_by() %>%
  summarize(AGG.D = sum(Demand)) -> AD


# Split Training & Testing dataset
ADTR <- AD %>% 
  filter(Quarter <= yearquarter("2016 Q4"))
ADTE <- AD %>% 
  filter(Quarter >= yearquarter("2017 Q1"))

agg_fit <- ADTR %>% 
           model(auto = ETS(AGG.D),
           AMod = ETS(AGG.D ~ trend("A")), 
           AdMod= ETS(AGG.D ~ trend("Ad")))

agg_fit %>% glance()
agg_fit %>% select(auto) %>% report()
```

```{r, warning=FALSE}
agg_fit %>% select(AMod) %>% report()
```

```{r, warning=FALSE}
agg_fit %>% select(AdMod) %>% report()
```

##### The best performing model on aggregate data as expected turns out to be Auto which is ETS(A, N, A). On the other hand, the best performing model with additive trend is ETS (A,A,A). Lastly, the best performing with Additive-damped trend ETS (A,Ad,A)

#### Q2. Now calculate the in-sample (training) and the out-of-sample (testing) metrics for each of the three models fitted in (1).

```{r}

agg_forecast <- agg_fit %>% forecast(h = 4)

rbind(agg_fit %>% accuracy(), 
     agg_forecast %>% accuracy(data = ADTE))
```

#### Q3. Using the model with the lowest out-of-sample *MAPE*, and using all data (i.e., the *AD* dataset) prepare a forecast for the four quarters of 2018 and report the point forecasts as well as the 80% and 95% confidence intervals.

From the previous output, we can see that the has the lowest out-of-sample MAPE for the aggregated model is *additive trend- AMod*

```{r}

agg_fit_aug <- agg_fit %>% augment()

agg_fit_aug_up <- agg_fit_aug %>% filter(.model == "AMod")

agg_forecast <- agg_fit %>% forecast(h = 4)

agg_fit_aug_up %>% autoplot(.vars = AGG.D, col = "red") + geom_point(data = agg_fit_aug_up, mapping = aes(y = .fitted))

agg_forecast %>% filter(.model == "AMod") %>% autoplot(ADTR) +
         geom_point(data = agg_fit_aug_up, mapping = aes(y = .fitted), col = "green") +
           geom_point(data = ADTE, mapping = aes(y = AGG.D), col = "blue")

fin_fit <- AD %>%  
  model(m.AAA = ETS(AGG.D ~ error("A")+trend("A")+season("A")))  
  
fin_forecast <- fin_fit %>% 
  forecast(h = 4)

fin_forecast %>%
  hilo(level =c(80,95)) %>%
  unpack_hilo("80%") %>%
  unpack_hilo("95%")
```

#### Q4. As in the hospitality business it is very costly to be short of personnel and your brand gets degraded when demand exceeds staffing capacity, we need to plan the staffing levels for each quarter according to a forecast of demand that we anticipate it will not be exceeded with a probability of 99%. What are these four quarterly demand levels?

```{r}
fin_forecast %>% mutate(Q99 = quantile(AGG.D, 0.99))
```

### Part II. Infrastructure Capacity Planning Forecast

As the resort infrastructure (e.g., buildings) and its direct fixed expenses cannot be moved across regions, it is important to carefully select the levels of capacity we should build in each region. To accomplish this we must forecast demand individually for each region, and then quantify the anticipated levels of occupation and the downside operational risk for each region.

#### Q5. Use the region-specific training and testing data (see code box below) and automatically select the ETS model that minimizes *AICc*, and as your colleague suggested also find the best model that includes an additive trend "A" and the best model that includes an additive-damped "Ad" trend as they may be preferred under the *BIC* criterion. Your *mable* should have 9 models in all; three models for each of the three regions. Report for each of the three models the corresponding *AICc* and *BIC* for each region. What is the ETS-name of the best model for each region according to the *AICc* information criterion? What is the best model for each region according to the *BIC* information criterion?

```{r}
# Break Region-Specific data into Training and Testing sets.
DTR <- D %>% 
  filter(Quarter <= yearquarter("2016 Q4"))
DTE <- D %>% 
  filter(Quarter >= yearquarter("2017 Q1"))

NorthC_DTR <- DTR %>% 
  filter(Region == "North Coast NSW")

NorthC_DTE <- DTE %>% 
  filter(Region == "North Coast NSW")

SouthC_DTR <- DTR %>% 
  filter(Region == "South Coast")

SouthC_DTE <- DTE %>% 
  filter(Region == "South Coast")

Syd_DTR <- DTR %>% 
  filter(Region == "Sydney")

Syd_DTE <- DTE %>% 
  filter(Region == "Sydney")

mod_fit <- DTR %>% 
      model(auto = ETS(Demand),
           AMod = ETS(Demand ~ trend("A")), 
           AdMod= ETS(Demand ~ trend("Ad")))

mod_fit %>% glance()   
forecast <- mod_fit %>% forecast(h = 4)
mod_fit_up <- DTR %>% model(auto = ETS(Demand))

#North Coast region
NorthC_fit <- NorthC_DTR %>% 
           model(auto = ETS(Demand),
           AMod = ETS(Demand ~ trend("A")), 
           AdMod= ETS(Demand ~ trend("Ad")))

NorthC_fit %>% glance()   
NorthC_fit %>% select(auto) %>% report()
```


```{r}
#South Coast region
SouthC_fit <- SouthC_DTR %>% 
           model(auto = ETS(Demand),
           AMod = ETS(Demand ~ trend("A")), 
           AdMod= ETS(Demand ~ trend("Ad")))

SouthC_fit %>% glance()
SouthC_fit %>% select(auto) %>% report()
```


```{r}
#Sydney region
Syd_fit <- Syd_DTR %>% 
           model(auto = ETS(Demand),
           AMod = ETS(Demand ~ trend("A")), 
           AdMod= ETS(Demand ~ trend("Ad")))

Syd_fit %>% glance()
Syd_fit %>% select(auto) %>% report()
```
##### From above it is clear that the best model for the North Coast region is auto which is ETS(M,N,M) based on the AICc and BIC values. Similarly for the South Coast region is automatically selected model which is ETS(M,N,M) as well. For Sydney, it is ETS(A,N,A) which was automatically selected.


####Q6. Calculate the in-sample (training) and the out-of-sample (testing) metrics for each of the nine models fitted in (5). Sometimes the damped models can introduce a bias in forecasting horizons longer than one or two periods. Is this a concern for the "AAdM"model for any of the three regions? Explain. Using for each region the model with the lowest *BIC*, and using all data (i.e., the D dataset) prepare a region-specific forecast for the four quarters of 2018 and report the point forecasts as well as the 80% and 95% confidence interval*

```{r}
#NorthCoast Region
NorthC_forecast <- NorthC_fit %>% forecast(h = 4)

rbind(NorthC_fit %>% accuracy(), 
      NorthC_forecast %>% accuracy(data = NorthC_DTE))

NorthC_fit_aug <- D %>% 
  filter(Region == "North Coast NSW") %>%  
  model(auto = ETS(Demand ~ error("M")+trend("N")+season("M")))  
  
NorthC_forecast_tot <- NorthC_fit_aug %>% forecast(h = 4)

NorthC_forecast_tot %>%
  hilo(level =c(80,95)) %>%
  unpack_hilo("80%") %>%
  unpack_hilo("95%")

#SouthCoast Region

SouthC_forecast <- SouthC_fit %>% forecast(h = 4)

rbind(SouthC_fit %>% accuracy(), 
      SouthC_forecast %>% accuracy(data = SouthC_DTE))

SouthC_fit_aug <- D %>% 
  filter(Region == "South Coast") %>%  
  model(auto = ETS(Demand ~ error("M")+trend("N")+season("M")))  
  
SouthC_forecast_tot <- SouthC_fit_aug %>% forecast(h = 4)

SouthC_forecast_tot %>%
  hilo(level =c(80,95)) %>%
  unpack_hilo("80%") %>%
  unpack_hilo("95%")

#Sydney Region

Syd_forecast <- Syd_fit %>% forecast(h = 4)

rbind(Syd_fit %>% accuracy(), 
      Syd_forecast %>% accuracy(data = Syd_DTE))

Syd_fit_aug <- D %>% 
  filter(Region == "Sydney") %>%  
  model(auto = ETS(Demand ~ error("A")+trend("N")+season("A")))  
  
Syd_forecast_tot <- Syd_fit_aug %>% forecast(h = 4)

Syd_forecast_tot %>%
  hilo(level =c(80,95)) %>%
  unpack_hilo("80%") %>%
  unpack_hilo("95%")

```

```{r}
reg_fit = mod_fit %>%  augment() 

reg_fit %>% autoplot(.vars = Demand, col = "black") + 
  geom_point(data = reg_fit, mapping = aes(y = .fitted))

reg_forecast = mod_fit %>% forecast(h = 4)

reg_forecast %>% autoplot(DTR) +
          geom_point(data = reg_fit, mapping = aes(y = .fitted), col = "green") +
          geom_point(data = DTE, mapping = aes(y = Demand), col = "blue")

overall = rbind(NorthC_fit_aug, SouthC_fit_aug, Syd_fit_aug)


reg_forecast = overall %>% forecast(h = 4)

reg_forecast
```
##### From the above output, we can infer that there is bias in the above mentioned model i.e AAdM. Highest bias is seen in Sydney, whereas, the bias is relatively lower in the North Coast region. The winner is South Coast as it seems to be fitting extremely well.*

### Q7. Is infrastructure (buildings, etc) cannot be modified from quarter to quarter, we must plan for capacity level for the entire year in each of the three regions. As with personnel, management thinks it is too expensive to be out of capacity to satisfy demand, and have proposed to build enough capacity to satisfy all demand of the highest season with a probability of 98%. What is the constant quarterly capacity that they should build in each region? If we define the mean-forecast occupancy rate as the occupancy rate implied by the mean forecast, prepare a table showing the mean-forecast occupancy rate for each of the four quarters at each of the three *regions.*

```{r}
NorthC_geo_2018 <- NorthC_forecast_tot %>% mutate(Q98 = quantile(Demand, 0.98)) 

cat('North Coast region-constant quarterly capacity: ')
NorthC_quarter_cap=max(NorthC_geo_2018$Q98)
NorthC_quarter_cap

SouthC_geo_2018 <- SouthC_forecast_tot %>% mutate(Q98 = quantile(Demand, 0.98)) 

cat('South Coast region-constant quarterly capacity: ')
SouthC_quarter_cap=max(SouthC_geo_2018$Q98)
SouthC_quarter_cap

Syd_geo_2018 <- Syd_forecast_tot %>% mutate(Q98 = quantile(Demand, 0.98)) 

cat('Sydney-constant quarterly capacity:')
Syd_quarter_cap=max(Syd_geo_2018$Q98)
Syd_quarter_cap

NorthC_geo_2018$ quarterly_cap = NorthC_quarter_cap
SouthC_geo_2018$ quarterly_cap = SouthC_quarter_cap
Syd_geo_2018$ quarterly_cap = Syd_quarter_cap

overall <- rbind(NorthC_geo_2018,SouthC_geo_2018,Syd_geo_2018) %>% as_tibble
overall$mean_forecast_occupancy = overall$`.mean`/overall$quarterly_cap

overall %>% select(Region,Quarter,`.mean`,quarterly_cap,mean_forecast_occupancy)
```

#### Q8. Another metric of interest is the 10%-down-side occupancy risk. This will be measured as the occupancy rate that would be obtained if actual demand is at the low 10% of the probability distribution of its forecast. What is the 10% level of the forecast probability distribution for each quarter at each region. Prepare also a table showing the 10%-downside-occupancy for each quarter at each region.

```{r}
overall %>% mutate(Q10 = quantile(Demand, 0.10)) %>% select(Region, State, Quarter, Demand, quarterly_cap, Q10)  %>% mutate(occupancy_rate = Q10/quarterly_cap)

```
